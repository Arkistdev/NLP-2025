{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9c84069b",
      "metadata": {},
      "source": [
        "## Eindopdracht 3: Moderne Netwerkarchitecturen\n",
        "Onno de Jong, 1909878"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "732ad686",
      "metadata": {
        "id": "732ad686"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0347285",
      "metadata": {
        "id": "a0347285"
      },
      "outputs": [],
      "source": [
        "with open(\"data/iliad.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    iliad = f.read().lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7ea024a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7ea024a0",
        "outputId": "dc404fb0-a01a-4a89-9502-f5deeae88152"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the project gutenberg ebook of the iliad\\n    \\nthis ebook is for the use of anyone anywhere in the united states and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iliad[:200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "53312ab5",
      "metadata": {
        "id": "53312ab5"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "    tokens: dict[str, int]\n",
        "    reverse_tokens: dict[int, str]\n",
        "    n: int\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tokens = {}\n",
        "        self.reverse_tokens = {}\n",
        "        self.n = 0\n",
        "\n",
        "    def train(self, data):\n",
        "        t = []\n",
        "        for x in data:\n",
        "            k = self.tokens.keys()\n",
        "            if x not in t:\n",
        "                t.append(x)\n",
        "\n",
        "        for index, x in enumerate(sorted(t)):\n",
        "            self.tokens[x] = index\n",
        "            self.reverse_tokens[index] = x\n",
        "\n",
        "        self.n = index + 1\n",
        "\n",
        "    def tokenize(self, data):\n",
        "        if hasattr(data, '__iter__') and len(data) > 1:\n",
        "            return [self.tokenize(x) for x in data]\n",
        "\n",
        "        if isinstance(data, str):\n",
        "            return self.tokens[data]\n",
        "\n",
        "    def decode(self, data):\n",
        "        if hasattr(data, '__iter__') and len(data) > 1:\n",
        "            return [self.decode(x) for x in data]\n",
        "\n",
        "        return self.reverse_tokens[data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b8f1a0b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8f1a0b5",
        "outputId": "21d610fc-e1c0-49f3-c5a3-72dd30f5b92a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '?': 27, '[': 28, ']': 29, '_': 30, 'a': 31, 'b': 32, 'c': 33, 'd': 34, 'e': 35, 'f': 36, 'g': 37, 'h': 38, 'i': 39, 'j': 40, 'k': 41, 'l': 42, 'm': 43, 'n': 44, 'o': 45, 'p': 46, 'q': 47, 'r': 48, 's': 49, 't': 50, 'u': 51, 'v': 52, 'w': 53, 'x': 54, 'y': 55, 'z': 56, '§': 57, 'à': 58, 'ä': 59, 'æ': 60, 'è': 61, 'é': 62, 'ê': 63, 'ë': 64, 'ï': 65, 'ò': 66, 'ô': 67, 'ö': 68, 'ù': 69, 'ü': 70, 'œ': 71, 'α': 72, 'β': 73, 'γ': 74, 'δ': 75, 'ε': 76, 'η': 77, 'θ': 78, 'ι': 79, 'κ': 80, 'λ': 81, 'μ': 82, 'ν': 83, 'ξ': 84, 'ο': 85, 'π': 86, 'ρ': 87, 'ς': 88, 'σ': 89, 'τ': 90, 'υ': 91, 'φ': 92, 'χ': 93, 'ω': 94, 'ἀ': 95, 'ἂ': 96, 'ἄ': 97, 'ἆ': 98, 'ἐ': 99, 'ἑ': 100, 'ἕ': 101, 'ἡ': 102, 'ἤ': 103, 'ἦ': 104, 'ἰ': 105, 'ἱ': 106, 'ἴ': 107, 'ἵ': 108, 'ἷ': 109, 'ὀ': 110, 'ὁ': 111, 'ὅ': 112, 'ὐ': 113, 'ὔ': 114, 'ὡ': 115, 'ὰ': 116, 'ά': 117, 'ὲ': 118, 'έ': 119, 'ὴ': 120, 'ή': 121, 'ὶ': 122, 'ί': 123, 'ὸ': 124, 'ό': 125, 'ὺ': 126, 'ύ': 127, 'ὼ': 128, 'ώ': 129, 'ᾳ': 130, 'ῆ': 131, 'ῇ': 132, 'ῖ': 133, 'ῤ': 134, 'ῦ': 135, 'ῳ': 136, 'ῶ': 137, 'ῷ': 138, '—': 139, '‘': 140, '’': 141, '“': 142, '”': 143, '•': 144, '™': 145}\n",
            "146\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.train(iliad)\n",
        "\n",
        "print(tokenizer.tokens)\n",
        "print(tokenizer.n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5465d354",
      "metadata": {
        "id": "5465d354"
      },
      "source": [
        "Correcte tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5960c7f0",
      "metadata": {
        "id": "5960c7f0"
      },
      "outputs": [],
      "source": [
        "def sliding_window(data, kernel_size, tokenizer):\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for i in range(0, len(data)-kernel_size, 1):\n",
        "        X.append(tokenizer.tokenize(data[i:i+kernel_size]))\n",
        "        Y.append(tokenizer.tokenize(data[i+kernel_size]))\n",
        "\n",
        "    X = np.vstack(X)\n",
        "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f58e224",
      "metadata": {
        "id": "2f58e224"
      },
      "source": [
        "Dataset opbouwen met de sliding window functie en normaliseren volgens aantal tokens in tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "23589de8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23589de8",
        "outputId": "7ea1cbc9-c7b5-484a-de36-658d3978de95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1116689, 100, 1)\n",
            "sample [[[0.34246575]\n",
            "  [0.26027397]\n",
            "  [0.23972603]\n",
            "  [0.00684932]\n",
            "  [0.31506849]\n",
            "  [0.32876712]\n",
            "  [0.30821918]\n",
            "  [0.2739726 ]\n",
            "  [0.23972603]\n",
            "  [0.2260274 ]\n",
            "  [0.34246575]\n",
            "  [0.00684932]\n",
            "  [0.25342466]\n",
            "  [0.34931507]\n",
            "  [0.34246575]\n",
            "  [0.23972603]\n",
            "  [0.30136986]\n",
            "  [0.21917808]\n",
            "  [0.23972603]\n",
            "  [0.32876712]\n",
            "  [0.25342466]\n",
            "  [0.00684932]\n",
            "  [0.23972603]\n",
            "  [0.21917808]\n",
            "  [0.30821918]\n",
            "  [0.30821918]\n",
            "  [0.28082192]\n",
            "  [0.00684932]\n",
            "  [0.30821918]\n",
            "  [0.24657534]\n",
            "  [0.00684932]\n",
            "  [0.34246575]\n",
            "  [0.26027397]\n",
            "  [0.23972603]\n",
            "  [0.00684932]\n",
            "  [0.26712329]\n",
            "  [0.28767123]\n",
            "  [0.26712329]\n",
            "  [0.21232877]\n",
            "  [0.23287671]\n",
            "  [0.        ]\n",
            "  [0.00684932]\n",
            "  [0.00684932]\n",
            "  [0.00684932]\n",
            "  [0.00684932]\n",
            "  [0.        ]\n",
            "  [0.34246575]\n",
            "  [0.26027397]\n",
            "  [0.26712329]\n",
            "  [0.33561644]\n",
            "  [0.00684932]\n",
            "  [0.23972603]\n",
            "  [0.21917808]\n",
            "  [0.30821918]\n",
            "  [0.30821918]\n",
            "  [0.28082192]\n",
            "  [0.00684932]\n",
            "  [0.26712329]\n",
            "  [0.33561644]\n",
            "  [0.00684932]\n",
            "  [0.24657534]\n",
            "  [0.30821918]\n",
            "  [0.32876712]\n",
            "  [0.00684932]\n",
            "  [0.34246575]\n",
            "  [0.26027397]\n",
            "  [0.23972603]\n",
            "  [0.00684932]\n",
            "  [0.34931507]\n",
            "  [0.33561644]\n",
            "  [0.23972603]\n",
            "  [0.00684932]\n",
            "  [0.30821918]\n",
            "  [0.24657534]\n",
            "  [0.00684932]\n",
            "  [0.21232877]\n",
            "  [0.30136986]\n",
            "  [0.37671233]\n",
            "  [0.30821918]\n",
            "  [0.30136986]\n",
            "  [0.23972603]\n",
            "  [0.00684932]\n",
            "  [0.21232877]\n",
            "  [0.30136986]\n",
            "  [0.37671233]\n",
            "  [0.3630137 ]\n",
            "  [0.26027397]\n",
            "  [0.23972603]\n",
            "  [0.32876712]\n",
            "  [0.23972603]\n",
            "  [0.00684932]\n",
            "  [0.26712329]\n",
            "  [0.30136986]\n",
            "  [0.00684932]\n",
            "  [0.34246575]\n",
            "  [0.26027397]\n",
            "  [0.23972603]\n",
            "  [0.00684932]\n",
            "  [0.34931507]\n",
            "  [0.30136986]]]\n",
            "target [39]\n"
          ]
        }
      ],
      "source": [
        "x, y = sliding_window(iliad, 100, tokenizer)\n",
        "samples = x / tokenizer.n\n",
        "print(samples.shape)\n",
        "print(\"sample\", samples[:1])\n",
        "print(\"target\", y[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b28b938",
      "metadata": {
        "id": "2b28b938"
      },
      "source": [
        "Converting targets naar one-hot encoded representatie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2c6a537f",
      "metadata": {
        "id": "2c6a537f"
      },
      "outputs": [],
      "source": [
        "targets = tf.keras.utils.to_categorical(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80984f19",
      "metadata": {
        "id": "80984f19"
      },
      "source": [
        "Model opbouwen en trainen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6e6c96f5",
      "metadata": {
        "id": "6e6c96f5"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input([100, 1]),\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(256),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(tokenizer.n, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1fe40227",
      "metadata": {
        "id": "1fe40227"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b2120ee9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2120ee9",
        "outputId": "b21fef01-eda1-47b6-a26c-db82ccab1027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.0949\n",
            "Epoch 1: loss improved from inf to 3.07672, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 30ms/step - loss: 3.0949\n",
            "Epoch 2/20\n",
            "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.9818\n",
            "Epoch 2: loss improved from 3.07672 to 2.89763, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 31ms/step - loss: 2.9818\n",
            "Epoch 3/20\n",
            "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.6853\n",
            "Epoch 3: loss improved from 2.89763 to 2.59758, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 31ms/step - loss: 2.6853\n",
            "Epoch 4/20\n",
            "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.4073\n",
            "Epoch 4: loss improved from 2.59758 to 2.36177, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 31ms/step - loss: 2.4073\n",
            "Epoch 5/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.2357\n",
            "Epoch 5: loss improved from 2.36177 to 2.20751, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 31ms/step - loss: 2.2357\n",
            "Epoch 6/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.1227\n",
            "Epoch 6: loss improved from 2.20751 to 2.10292, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 31ms/step - loss: 2.1227\n",
            "Epoch 7/20\n",
            "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.0485\n",
            "Epoch 7: loss improved from 2.10292 to 2.03594, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 31ms/step - loss: 2.0484\n",
            "Epoch 8/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.9873\n",
            "Epoch 8: loss improved from 2.03594 to 1.97664, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 31ms/step - loss: 1.9873\n",
            "Epoch 9/20\n",
            "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.9369\n",
            "Epoch 9: loss improved from 1.97664 to 1.92964, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 31ms/step - loss: 1.9369\n",
            "Epoch 10/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.8957\n",
            "Epoch 10: loss improved from 1.92964 to 1.89575, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 31ms/step - loss: 1.8957\n",
            "Epoch 11/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.9324\n",
            "Epoch 11: loss did not improve from 1.89575\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 31ms/step - loss: 1.9324\n",
            "Epoch 12/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.8569\n",
            "Epoch 12: loss improved from 1.89575 to 1.85650, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 31ms/step - loss: 1.8569\n",
            "Epoch 13/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.8478\n",
            "Epoch 13: loss improved from 1.85650 to 1.83790, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 31ms/step - loss: 1.8478\n",
            "Epoch 14/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.8185\n",
            "Epoch 14: loss improved from 1.83790 to 1.82490, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 31ms/step - loss: 1.8185\n",
            "Epoch 15/20\n",
            "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.8089\n",
            "Epoch 15: loss improved from 1.82490 to 1.80619, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 31ms/step - loss: 1.8089\n",
            "Epoch 16/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.7860\n",
            "Epoch 16: loss improved from 1.80619 to 1.78635, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 31ms/step - loss: 1.7860\n",
            "Epoch 17/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.7694\n",
            "Epoch 17: loss improved from 1.78635 to 1.76791, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 31ms/step - loss: 1.7694\n",
            "Epoch 18/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.7559\n",
            "Epoch 18: loss improved from 1.76791 to 1.75428, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 31ms/step - loss: 1.7559\n",
            "Epoch 19/20\n",
            "\u001b[1m8724/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.7406\n",
            "Epoch 19: loss improved from 1.75428 to 1.74062, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 31ms/step - loss: 1.7406\n",
            "Epoch 20/20\n",
            "\u001b[1m8723/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.7259\n",
            "Epoch 20: loss improved from 1.74062 to 1.72669, saving model to ./models/model.keras\n",
            "\u001b[1m8725/8725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 31ms/step - loss: 1.7259\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eff86cd5190>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(samples, targets, batch_size=128, epochs=20, callbacks=[tf.keras.callbacks.ModelCheckpoint(\"./models/model.keras\", monitor='loss', verbose=1, save_best_only=True, mode='min')])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4069370b",
      "metadata": {
        "id": "4069370b"
      },
      "source": [
        "Trainen duurde erg lang, na een tijdje te klooien met wsl en cuda heb ik het uiteindelijk aan de praat gekregen op google collab. ~4 minuten per epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "50a6d780",
      "metadata": {
        "id": "50a6d780"
      },
      "outputs": [],
      "source": [
        "best_model = tf.keras.models.load_model(\"./models/model.keras\", compile=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "eeba221f",
      "metadata": {
        "id": "eeba221f"
      },
      "outputs": [],
      "source": [
        "def predict(seq, n):\n",
        "    for _ in range(n):\n",
        "        sample = np.squeeze(seq[-100:])\n",
        "        # print(tokenizer.decode(list(sample)))\n",
        "        sample = (sample / tokenizer.n).reshape(1, 100, 1) # Take last 100 characters\n",
        "        pred = np.squeeze(best_model.predict(sample, verbose=0)) # Remove empty dimensions\n",
        "        pred_int = int(tf.math.argmax(pred))\n",
        "        seq.append(np.array([pred_int]))\n",
        "\n",
        "    seq = np.squeeze(seq)\n",
        "\n",
        "    print(\"Original sample:\\n\", \"\".join(tokenizer.decode(seq[:100])))\n",
        "    print(\"\")\n",
        "    print(\"Volledig voorspelde sample:\\n\", \"\".join(tokenizer.decode(seq)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b6a49f3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6a49f3e",
        "outputId": "a0788e03-7ae2-4f25-e16a-8968b5c97208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sample:\n",
            "  casting his spear at mars\n",
            " juno\n",
            " hector chiding paris\n",
            " the meeting of hector and andromache\n",
            " bows a\n",
            "\n",
            "Volledig voorspelde sample:\n",
            "  casting his spear at mars\n",
            " juno\n",
            " hector chiding paris\n",
            " the meeting of hector and andromache\n",
            " bows and the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears\n"
          ]
        }
      ],
      "source": [
        "predict(list(x[2000]), 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ff0c397",
      "metadata": {
        "id": "9ff0c397",
        "outputId": "d5088539-a500-427f-ba09-e5c15f9dce8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sample:\n",
            " ere thy sway the curse of meaner powers,\n",
            "and thou the shame of any host but ours!\n",
            "a host, by jove en\n",
            "\n",
            "Volledig voorspelde sample:\n",
            " ere thy sway the curse of meaner powers,\n",
            "and thou the shame of any host but ours!\n",
            "a host, by jove ene the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the th\n"
          ]
        }
      ],
      "source": [
        "predict(list(x[6000]), 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "61eb91f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61eb91f3",
        "outputId": "0fc9a33f-7c81-4f3f-9d07-b201ac0a4993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sample:\n",
            " f ithagenes.\n",
            "although poor, he married, and the result of the union was a girl named\n",
            "critheïs. the g\n",
            "\n",
            "Volledig voorspelde sample:\n",
            " f ithagenes.\n",
            "although poor, he married, and the result of the union was a girl named\n",
            "critheïs. the gods and sound the sanks of his conpuest of the sanks of his the sage of high;\n",
            "the sanks of his the sanks of his the sage of homes and saised the sanks of his the sanks of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears \n"
          ]
        }
      ],
      "source": [
        "predict(list(x[9000]), 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f39e184e",
      "metadata": {
        "id": "f39e184e"
      },
      "source": [
        "Het is nog niet bepaald een woordentovenaar... Hij herhaald heel de tijd dezelfde woorden. Hij heeft in ieder geval een paar woorden geleerd.\n",
        "In de laatste sample zie je wel dat hij een echt stukje tekst heeft gemaakt \"the gods and sound the sanks of his conpuest of the sanks of his the sage of high;\" Niet dat dit stukje tekst ergens op slaat maar er bepaalde patronen zoals de spelling van de woorden en de zins structuur die zeker laten zien dat er iets getrained is\n",
        "\n",
        "Een paar verbeteringen zouden zijn:\n",
        "- (veel) Langere training tijden. Grote LLM's worden getrained verspreid over honderden gpus voor duizenden uren. Maar in dit geval met deze architectuur weet ik niet hoeveel er uit te halen is meer nog langer trainen.\n",
        "- Betere tokenizer. In de ervaring die ik met het trainen/finetunen van grotere modellen heb is dat de tokenizer grotere tokens heeft. Dus ook kleine veelgebruikte woorden en woord-delen.\n",
        "- Een grotere, gevarieerde trainingset zou ook helpen met het verbeteren van het model\n",
        "- andere architectuur. Het model dat we nu hebben heeft niet heel erg veel weights, een groter model zou meer nuances eruit kunnen halen denk ik. Ook de architectuur van een LSTM kan worden verbetered door bijvoorbeeld naar een transformer model te gaan zoals chatgpt of een mixture of experts (MoE) zoals mixtral"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c6f619d",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
